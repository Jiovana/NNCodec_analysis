=== Summary per quantization === OLD PATH
           compression_ratio        compression_gain_pct         bits_per_element       
                        mean    std                 mean     std             mean    std
bits_quant
8                      1.503  0.589               28.210  15.024            5.743  1.202
16                     1.152  0.117               12.482   7.459           14.003  1.194

Descriptive statistics for Compression Ratio grouped by bits_quant:
            count      mean       std       min       25%       50%       75%       max
bits_quant                                                                      
8           199.0  1.503468  0.588595  1.036437  1.224849  1.347368  1.504487   4.673511
16          199.0  1.152447  0.117110  1.004578  1.087740  1.126455  1.176920   1.644972    

=== Global Summary (Total Bytes) === BERT MODEL
   bits_quant  raw_total_bytes  compressed_total_bytes  overall_ratio  overall_gain_pct
0           8        109482240                62313082       1.756970         43.083844
1          16        218964480               174274319       1.256436         20.409777

=== Overall Summary (Mean/Std) ===
   bits_quant  mean_ratio  std_ratio  mean_gain   std_gain     mean_nmse      std_nmse
0           8    1.503468   0.588595  28.209505  15.023693  5.337389e-03  2.119500e-02
1          16    1.152447   0.117110  12.482499   7.459427  8.017350e-08  3.187292e-07

=== Per Tensor Type ===
   bits_quant  tensor_type  mean_ratio  std_ratio  mean_gain   std_gain   mean_bpe   std_bpe     mean_nmse      std_nmse  total_elems
0           8         bias    1.312209   0.200459  22.179594  10.845470   6.225632  0.867638  4.617475e-04  4.782778e-04       102912        
1           8    embedding    2.106476   0.761570  46.660064  22.138892   4.267195  1.771111  5.787321e-03  8.220798e-03     23836416        
2           8  norm_weight    1.488897   0.226424  31.336806  10.328735   5.493056  0.826299  4.239931e-03  1.840410e-03        18432        
3           8       weight    1.731976   0.857344  34.265310  17.288568   5.258775  1.383085  1.221892e-02  3.391739e-02     85524480        
4          16         bias    1.110504   0.065644   9.645382   5.231845  14.456739  0.837095  6.917845e-09  7.172997e-09       102912        
5          16    embedding    1.303364   0.173961  22.177579  10.998285  12.451587  1.759726  8.654565e-08  1.237230e-07     23836416        
6          16  norm_weight    1.130364   0.044520  11.406793   3.346929  14.174913  0.535509  6.332260e-08  2.857092e-08        18432        
7          16       weight    1.207744   0.151966  16.113652   8.808606  13.421816  1.409377  1.837076e-07  5.100300e-07     85524480        

=== Per Layer (Transformer) ===
    bits_quant  layer_id  mean_ratio  mean_gain   mean_bpe     mean_nmse
0            8         0    1.437042  27.857863   5.771371  1.743559e-03
1            8         1    1.432293  27.508648   5.799308  1.866807e-03
2            8         2    1.432833  26.347192   5.892225  3.206498e-03
3            8         3    1.531374  26.719448   5.862444  9.987117e-03
4            8         4    1.534921  26.852571   5.851794  1.023173e-02
5            8         5    1.535075  28.042801   5.756576  8.517588e-03
6            8         6    1.487600  27.026945   5.837844  5.831161e-03
7            8         7    1.499291  28.790312   5.696775  4.236606e-03
8            8         8    1.505946  29.926546   5.605876  3.585486e-03
9            8         9    1.453232  27.781736   5.777461  2.965691e-03
10           8        10    1.643733  31.449286   5.484057  1.052670e-02
11           8        11    1.413755  25.921837   5.926253  2.128058e-03
12          16         0    1.147806  12.427876  14.011540  2.625489e-08
13          16         1    1.144081  12.182299  14.050832  2.813933e-08
14          16         2    1.146450  12.163125  14.053900  4.839495e-08
15          16         3    1.145812  11.769512  14.116878  1.499220e-07
16          16         4    1.154387  12.364128  14.021740  1.541373e-07
17          16         5    1.152006  12.366597  14.021345  1.274447e-07
18          16         6    1.143347  11.790280  14.113555  8.780185e-08
19          16         7    1.154097  12.699511  13.968078  6.297962e-08
20          16         8    1.152316  12.620514  13.980718  5.447871e-08
21          16         9    1.146896  12.253682  14.039411  4.461201e-08
22          16        10    1.171587  13.569964  13.828806  1.578026e-07
23          16        11    1.134673  11.275787  14.195874  3.193909e-08

==================================================================================================================
=== Global Summary (Total Bytes) === GPT MODEL
   bits_quant  raw_total_bytes  compressed_total_bytes  overall_ratio  overall_gain_pct
0           8        116534784                55271455       2.108408         52.570852
1          16        233069568               173686088       1.341901         25.478865

=== Overall Summary (Mean/Std) ===
   bits_quant  mean_ratio  std_ratio  mean_gain   std_gain     mean_nmse  std_nmse
0           8    2.305986   2.332667  42.273643  18.919041  2.885490e-02  0.106315
1          16    1.268531   0.192194  19.665608  10.173620  5.224863e-07  0.000002

=== Per Tensor Type ===
   bits_quant tensor_type  mean_ratio  std_ratio  mean_gain   std_gain   mean_bpe   std_bpe     mean_nmse      std_nmse  total_elems
0           8        bias    1.814768   0.918361  38.473548  16.808071   4.922116  1.344646  9.430567e-04  1.013449e-03       101376
1           8      weight    2.783928   3.085175  45.971032  20.201114   4.322317  1.616089  5.601237e-02  1.446848e-01    116433408
2          16        bias    1.238656   0.155105  18.148314   9.214653  13.096270  1.474344  1.398070e-08  1.341546e-08       101376
3          16      weight    1.297598   0.219626  21.141894  10.886864  12.617297  1.741898  1.017248e-06  2.776094e-06    116433408

=== Per Layer (Transformer) ===
    bits_quant  layer_id  mean_ratio  mean_gain   mean_bpe     mean_nmse
0            8         0    1.720902  36.594412   5.072447  4.671564e-03
1            8         1    2.001072  39.077415   4.873807  2.012228e-02
2            8         2    2.280710  41.546173   4.676306  3.760481e-02
3            8         3    2.965716  41.320581   4.694354  5.005562e-02
4            8         4    1.963226  37.857813   4.971375  2.228544e-02
5            8         5    1.878402  40.134096   4.789272  1.139185e-02
6            8         6    2.218894  42.848058   4.572155  3.015793e-02
7            8         7    2.574755  43.708667   4.503307  4.392734e-02
8            8         8    2.817229  44.145339   4.468373  4.731711e-02
9            8         9    2.541445  46.266211   4.298703  4.636671e-02
10           8        10    2.845275  49.463423   4.042926  3.217519e-02
11           8        11    1.944380  43.833689   4.493305  4.631042e-03
12          16         0    1.237597  17.983946  13.122569  7.036409e-08
13          16         1    1.252489  18.564925  13.029612  3.138388e-07
14          16         2    1.270265  19.768952  12.836968  6.501639e-07
15          16         3    1.267948  19.227767  12.923557  1.117887e-06
17          16         5    1.247678  18.880402  12.979136  1.720357e-07
19          16         7    1.267268  19.544793  12.872833  8.372066e-07
20          16         8    1.273922  19.836620  12.826141  9.578420e-07
21          16         9    1.282806  20.743622  12.681020  8.193191e-07
22          16        10    1.336182  22.860494  12.342321  5.059948e-07
23          16        11    1.269151  20.198523  12.768236  6.939322e-08